{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "<table style=\"border: none\" align=\"center\">\n   <tr style=\"border: none\">\n      <th style=\"border: none\"><font face=\"verdana\" size=\"4\" color=\"black\"><b>Network Intrusion Detection</b></font></th>\n      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n   </tr> \n   <tr style=\"border: none\">\n       <td style=\"border: none\"><img src=\"https://github.com/pmservice/wml-sample-models/raw/master/tensorflow/hand-written-digit-recognition/images/experiment_banner.png\" width=\"600\" height = \"200\" alt=\"Icon\"></td>\n   </tr>\n</table>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "This notebook contains steps and code to use Spark ML library to build classification models using kddcup data.\n\n**Notebook environment:** Scala 2.11 + Spark 2.2\n\n**Platform:** IBM Watson Studio\n\n**Dataset:**\n[UCI kddcup data](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) (743MB)\n\n**Purpose:**\nBuild algorithms that can detect the network intrusions.\n\n**Classification algorithms:**\n- Random Forest Classifier\n- Multilayer Perceptron Classifier\n\n**Contents: **\n\nThis notebook contains the following parts:\n\n1.\t[Download data](#download)\n2.\t[Load and prepare data](#load)\n3.\t[Building models](#model)\n  * [Random Forest](#rf)\n  * [MLP](#mlp)\n\n\n<a id=\"download\"></a>\n## Download data\nWatson Studio's community has many different data sources. We can download the data from the community. In community, search \"KDD\" and open the \"KDDCUP\" dataset, click on the link button to get the URL.\n\nWe firstly download the zipped file to Watson's shared directory */opt/ibm/user-libs/shared-data*. If the \"shared-data\" folder doesn't exist, try to execute the commented code to create the folder.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "import urllib.request \n\n# !mkdir /opt/ibm/user-libs/shared-data/\nurl = \"https://dataplatform.ibm.com/exchange-api/v1/entries/1438a61212a64ac435c837ba046efc19/data?accessKey=903188bb984a30f38bb889102a7db39f\"\nfilename = \"/opt/ibm/user-libs/shared-data/kddcup.zip\"\nurllib.request.urlretrieve(url, filename)"
        }, 
        {
            "source": "**Unzip**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!mkdir /opt/ibm/user-libs/shared-data/kddcup\n!unzip /opt/ibm/user-libs/shared-data/kddcup.zip -d /opt/ibm/user-libs/shared-data/kddcup/"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls /opt/ibm/user-libs/shared-data/kddcup/"
        }, 
        {
            "source": "**We use the entire dataset kddcup.data (743MB) , use *gunzip* to unzip the file to the same directory.**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!gunzip /opt/ibm/user-libs/shared-data/kddcup/kddcup.data.gz -d /opt/ibm/user-libs/shared-data/kddcup/kddcup.data"
        }, 
        {
            "source": "<a id=\"load\"></a>\n## Load and prepare data\nThe data is comma splited, so we can directly use SparkSession to read the data as dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20180622194457-0001\n+---+---+----+---+---+-----+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-------+\n|_c0|_c1| _c2|_c3|_c4|  _c5|_c6|_c7|_c8|_c9|_c10|_c11|_c12|_c13|_c14|_c15|_c16|_c17|_c18|_c19|_c20|_c21|_c22|_c23|_c24|_c25|_c26|_c27|_c28|_c29|_c30|_c31|_c32|_c33|_c34|_c35|_c36|_c37|_c38|_c39|_c40|   _c41|\n+---+---+----+---+---+-----+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-------+\n|  0|tcp|http| SF|215|45076|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   1| 0.0| 0.0| 0.0| 0.0| 1.0| 0.0| 0.0|   0|   0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0|normal.|\n|  0|tcp|http| SF|162| 4528|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   2|   2| 0.0| 0.0| 0.0| 0.0| 1.0| 0.0| 0.0|   1|   1| 1.0| 0.0| 1.0| 0.0| 0.0| 0.0| 0.0| 0.0|normal.|\n|  0|tcp|http| SF|236| 1228|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   1| 0.0| 0.0| 0.0| 0.0| 1.0| 0.0| 0.0|   2|   2| 1.0| 0.0| 0.5| 0.0| 0.0| 0.0| 0.0| 0.0|normal.|\n|  0|tcp|http| SF|233| 2032|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   2|   2| 0.0| 0.0| 0.0| 0.0| 1.0| 0.0| 0.0|   3|   3| 1.0| 0.0|0.33| 0.0| 0.0| 0.0| 0.0| 0.0|normal.|\n|  0|tcp|http| SF|239|  486|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   3|   3| 0.0| 0.0| 0.0| 0.0| 1.0| 0.0| 0.0|   4|   4| 1.0| 0.0|0.25| 0.0| 0.0| 0.0| 0.0| 0.0|normal.|\n+---+---+----+---+---+-----+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\ndf = spark.read\\\n  .format('csv')\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(\"/opt/ibm/user-libs/shared-data/kddcup/kddcup.data\")\ndf.show(5)"
        }, 
        {
            "source": "**Let's take a look at the schema and labels(the last column\"_c41\").**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 2, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<bound method DataFrame.printSchema of DataFrame[_c0: int, _c1: string, _c2: string, _c3: string, _c4: int, _c5: int, _c6: int, _c7: int, _c8: int, _c9: int, _c10: int, _c11: int, _c12: int, _c13: int, _c14: int, _c15: int, _c16: int, _c17: int, _c18: int, _c19: int, _c20: int, _c21: int, _c22: int, _c23: int, _c24: double, _c25: double, _c26: double, _c27: double, _c28: double, _c29: double, _c30: double, _c31: int, _c32: int, _c33: double, _c34: double, _c35: double, _c36: double, _c37: double, _c38: double, _c39: double, _c40: double, _c41: string]>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "df.printSchema"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+----------------+-------+\n|            _c41|  count|\n+----------------+-------+\n|    warezmaster.|     20|\n|          smurf.|2807886|\n|            pod.|    264|\n|           imap.|     12|\n|           nmap.|   2316|\n|   guess_passwd.|     53|\n|        ipsweep.|  12481|\n|      portsweep.|  10413|\n|          satan.|  15892|\n|           land.|     21|\n|     loadmodule.|      9|\n|      ftp_write.|      8|\n|buffer_overflow.|     30|\n|        rootkit.|     10|\n|    warezclient.|   1020|\n|       teardrop.|    979|\n|           perl.|      3|\n|            phf.|      4|\n|       multihop.|      7|\n|        neptune.|1072017|\n+----------------+-------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "df.select(\"_c41\").groupBy(\"_c41\").count().show()"
        }, 
        {
            "source": "**According to the [description](http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types), we should recode the labels into five categories. We can use a SQL query to do this. Name the new column name as \"label_s\" stands for *label in string*.**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-------+-------+\n|label_s|  count|\n+-------+-------+\n|    u2r|     52|\n| normal| 972781|\n|    r2l|   1126|\n|  probe|  41102|\n|    dos|3883370|\n+-------+-------+\n\n"
                }
            ], 
            "source": "df.createOrReplaceTempView(\"attack\")\nquery = \"\"\"SELECT *, \n    CASE _c41 \n        WHEN 'back.' THEN 'dos'\n        WHEN 'buffer_overflow.' THEN 'u2r'\n        WHEN 'ftp_write.' THEN 'r2l'\n        WHEN 'guess_passwd.' THEN 'r2l'\n        WHEN 'imap.' THEN 'r2l'\n        WHEN 'ipsweep.' THEN 'probe'\n        WHEN 'land.' THEN 'dos'\n        WHEN 'loadmodule.' THEN 'u2r'\n        WHEN 'multihop.' THEN 'r2l'\n        WHEN 'neptune.' THEN 'dos'\n        WHEN 'nmap.' THEN 'probe'\n        WHEN 'perl.' THEN 'u2r'\n        WHEN 'phf.' THEN 'r2l'\n        WHEN 'pod.' THEN 'dos'\n        WHEN 'portsweep.' THEN 'probe'\n        WHEN 'rootkit.' THEN 'u2r'\n        WHEN 'satan.' THEN 'probe'\n        WHEN 'smurf.' THEN 'dos'\n        WHEN 'spy.' THEN 'r2l'\n        WHEN 'teardrop.' THEN 'dos'\n        WHEN 'warezclient.' THEN 'r2l'\n        WHEN 'warezmaster.' THEN 'r2l'\n        ELSE 'normal'\nEND AS label_s \nFROM attack\"\"\"\n\nlabeled = spark.sql(query)\nlabeled.select(\"label_s\").groupBy(\"label_s\").count().show()"
        }, 
        {
            "source": "**Intuitively, we should split the data into *training* and *testing* sets before building ML pipeline. However, the number of categories for those categorical variables may be different between two sets. It will cause errors in building algorithms.**\n\nTherefore, we build a pipeline to prepare the data before splitting it to avoid errors.\n\n**The pipeline:**\n* StringIndexers: the c1, c2, c3 are categorical strings, we need to firstly index them\n* OneHotEncoders: after the categorical strings are indexed, we can now perform one-hot encoding to the indexed columns\n* VectorAssembler: Include the wanted columns and assemble them as a feature vector\n* labelIndexer: another StringIndexer to index the label_s column and output as \"label\" column", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler, OneHotEncoder\nfrom pyspark.ml import Pipeline\nindexer1 = StringIndexer(inputCol=\"_c1\", outputCol=\"i_c1\")\nindexer2 = StringIndexer(inputCol=\"_c2\", outputCol=\"i_c2\")\nindexer3 = StringIndexer(inputCol=\"_c3\", outputCol=\"i_c3\")\n\nencoder1 = OneHotEncoder(inputCol=\"i_c1\", outputCol=\"v_c1\")\nencoder2 = OneHotEncoder(inputCol=\"i_c2\", outputCol=\"v_c2\")\nencoder3 = OneHotEncoder(inputCol=\"i_c3\", outputCol=\"v_c3\")\n\nfeaturenames = [\"_c0\", \"v_c1\", \"v_c2\", \"v_c3\", \"_c4\", \"_c5\", \"_c6\", \n                         \"_c7\", \"_c8\", \"_c9\", \"_c10\", \"_c11\", \"_c12\", \"_c13\", \n                         \"_c14\", \"_c15\", \"_c16\", \"_c17\", \"_c18\", \"_c19\",\n                         \"_c22\", \"_c23\", \"_c24\", \"_c25\", \"_c26\", \"_c27\", \n                         \"_c28\", \"_c29\", \"_c30\", \"_c31\", \"_c32\", \"_c33\", \"_c34\", \n                         \"_c35\", \"_c36\", \"_c37\", \"_c38\", \"_c39\", \"_c40\"]\nassembler = VectorAssembler(inputCols=featurenames, outputCol=\"features\")\n\nlabelIndexer = StringIndexer(inputCol=\"label_s\", outputCol=\"label\")\n\npipeline_prepare = Pipeline(stages=[indexer1,indexer2,indexer3,encoder1,encoder2,encoder3,assembler,labelIndexer])\n"
        }, 
        {
            "source": "**Fit and transform the data**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "prepare = pipeline_prepare.fit(labeled)\ndata = prepare.transform(labeled)"
        }, 
        {
            "source": "<a id=\"build\"></a>\n## Building models\n**Firstly we split the data, because the data is rather big, I choose 60% of the data to be training set and the rest goes to testing set**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "(train, test) = data.randomSplit([0.6, 0.4])"
        }, 
        {
            "source": "<a id=\"rf\"></a>\n### Random Forest\nLet's start with random forest algorithm. Spark ML provides this algorithm and the only thing we need to do it set it up. One thing we need to notice is that there are 70 categories in c2 column, so the default _MaxBins_ is not enough (it has to be larger than the biggest number of categories of all categorical variables). We set the _MaxBins_ to be 72 to avoid errors. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=5, maxBins=72)"
        }, 
        {
            "source": "**Train and fit the model to test data**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Training process takes 380.5171010494232 secs\n"
                }
            ], 
            "source": "import time\nstart_time = time.time()\nrf_model = rf.fit(train)\nprint(\"Training process takes %s secs\" % (time.time() - start_time))"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "RandomForestClassificationModel (uid=RandomForestClassifier_494480e853acbfe78808) with 5 trees\n  Tree 0 (weight 1.0):\n    If (feature 89 <= 0.0)\n     If (feature 8 in {0.0})\n      If (feature 98 <= 8.0)\n       If (feature 112 <= 0.4)\n        If (feature 109 <= 0.04)\n         Predict: 1.0\n        Else (feature 109 > 0.04)\n         Predict: 1.0\n       Else (feature 112 > 0.4)\n        If (feature 72 in {0.0})\n         Predict: 2.0\n        Else (feature 72 not in {0.0})\n         Predict: 2.0\n      Else (feature 98 > 8.0)\n       If (feature 105 <= 0.5)\n        If (feature 75 in {0.0})\n         Predict: 0.0\n        Else (feature 75 not in {0.0})\n         Predict: 2.0\n       Else (feature 105 > 0.5)\n        If (feature 7 in {0.0})\n         Predict: 2.0\n        Else (feature 7 not in {0.0})\n         Predict: 2.0\n     Else (feature 8 not in {0.0})\n      If (feature 0 <= 0.0)\n       If (feature 105 <= 0.11)\n        Predict: 1.0\n       Else (feature 105 > 0.11)\n        If (feature 107 <= 254.0)\n         Predict: 1.0\n        Else (feature 107 > 254.0)\n         Predict: 1.0\n      Else (feature 0 > 0.0)\n       Predict: 1.0\n    Else (feature 89 > 0.0)\n     If (feature 116 <= 0.01)\n      If (feature 108 <= 39.0)\n       If (feature 111 <= 0.99)\n        If (feature 83 <= 1771.0)\n         Predict: 1.0\n        Else (feature 83 > 1771.0)\n         Predict: 1.0\n       Else (feature 111 > 0.99)\n        If (feature 5 in {0.0})\n         Predict: 3.0\n        Else (feature 5 not in {0.0})\n         Predict: 1.0\n      Else (feature 108 > 39.0)\n       If (feature 87 <= 19.0)\n        If (feature 111 <= 0.99)\n         Predict: 1.0\n        Else (feature 111 > 0.99)\n         Predict: 1.0\n       Else (feature 87 > 19.0)\n        Predict: 1.0\n     Else (feature 116 > 0.01)\n      If (feature 87 <= 0.0)\n       If (feature 90 <= 0.0)\n        If (feature 9 in {0.0})\n         Predict: 1.0\n        Else (feature 9 not in {0.0})\n         Predict: 1.0\n       Else (feature 90 > 0.0)\n        If (feature 109 <= 0.03)\n         Predict: 1.0\n        Else (feature 109 > 0.03)\n         Predict: 1.0\n      Else (feature 87 > 0.0)\n       If (feature 112 <= 0.0)\n        If (feature 109 <= 0.99)\n         Predict: 1.0\n        Else (feature 109 > 0.99)\n         Predict: 0.0\n       Else (feature 112 > 0.0)\n        If (feature 111 <= 0.99)\n         Predict: 1.0\n        Else (feature 111 > 0.99)\n         Predict: 1.0\n  Tree 1 (weight 1.0):\n    If (feature 89 <= 0.0)\n     If (feature 74 in {0.0})\n      If (feature 111 <= 0.99)\n       If (feature 100 <= 0.44)\n        If (feature 102 <= 0.0)\n         Predict: 1.0\n        Else (feature 102 > 0.0)\n         Predict: 0.0\n       Else (feature 100 > 0.44)\n        If (feature 111 <= 0.1)\n         Predict: 0.0\n        Else (feature 111 > 0.1)\n         Predict: 2.0\n      Else (feature 111 > 0.99)\n       If (feature 7 in {0.0})\n        If (feature 3 in {0.0})\n         Predict: 2.0\n        Else (feature 3 not in {0.0})\n         Predict: 0.0\n       Else (feature 7 not in {0.0})\n        If (feature 75 in {0.0})\n         Predict: 1.0\n        Else (feature 75 not in {0.0})\n         Predict: 2.0\n     Else (feature 74 not in {0.0})\n      If (feature 105 <= 0.0)\n       If (feature 110 <= 0.4)\n        If (feature 113 <= 0.12)\n         Predict: 1.0\n        Else (feature 113 > 0.12)\n         Predict: 2.0\n       Else (feature 110 > 0.4)\n        If (feature 5 in {0.0})\n         Predict: 2.0\n        Else (feature 5 not in {0.0})\n         Predict: 2.0\n      Else (feature 105 > 0.0)\n       If (feature 43 in {0.0})\n        If (feature 111 <= 0.05)\n         Predict: 0.0\n        Else (feature 111 > 0.05)\n         Predict: 2.0\n       Else (feature 43 not in {0.0})\n        Predict: 0.0\n    Else (feature 89 > 0.0)\n     If (feature 9 in {0.0})\n      If (feature 102 <= 0.12)\n       If (feature 87 <= 1.0)\n        If (feature 93 <= 1.0)\n         Predict: 1.0\n        Else (feature 93 > 1.0)\n         Predict: 1.0\n       Else (feature 87 > 1.0)\n        If (feature 90 <= 0.0)\n         Predict: 1.0\n        Else (feature 90 > 0.0)\n         Predict: 0.0\n      Else (feature 102 > 0.12)\n       If (feature 83 <= 4541.0)\n        If (feature 82 <= 1233.0)\n         Predict: 1.0\n        Else (feature 82 > 1233.0)\n         Predict: 0.0\n       Else (feature 83 > 4541.0)\n        If (feature 112 <= 0.0)\n         Predict: 1.0\n        Else (feature 112 > 0.0)\n         Predict: 1.0\n     Else (feature 9 not in {0.0})\n      If (feature 0 <= 3.0)\n       If (feature 111 <= 0.99)\n        If (feature 102 <= 0.0)\n         Predict: 1.0\n        Else (feature 102 > 0.0)\n         Predict: 1.0\n       Else (feature 111 > 0.99)\n        If (feature 105 <= 0.0)\n         Predict: 3.0\n        Else (feature 105 > 0.0)\n         Predict: 1.0\n      Else (feature 0 > 3.0)\n       If (feature 112 <= 0.06)\n        If (feature 105 <= 0.0)\n         Predict: 1.0\n        Else (feature 105 > 0.0)\n         Predict: 3.0\n       Else (feature 112 > 0.06)\n        If (feature 106 <= 0.0)\n         Predict: 3.0\n        Else (feature 106 > 0.0)\n         Predict: 3.0\n  Tree 2 (weight 1.0):\n    If (feature 5 in {0.0})\n     If (feature 96 <= 0.0)\n      If (feature 6 in {0.0})\n       If (feature 83 <= 0.0)\n        If (feature 1 in {0.0})\n         Predict: 0.0\n        Else (feature 1 not in {0.0})\n         Predict: 0.0\n       Else (feature 83 > 0.0)\n        If (feature 76 in {0.0})\n         Predict: 1.0\n        Else (feature 76 not in {0.0})\n         Predict: 1.0\n      Else (feature 6 not in {0.0})\n       If (feature 113 <= 0.92)\n        If (feature 103 <= 0.5)\n         Predict: 1.0\n        Else (feature 103 > 0.5)\n         Predict: 0.0\n       Else (feature 113 > 0.92)\n        If (feature 99 <= 4.0)\n         Predict: 0.0\n        Else (feature 99 > 4.0)\n         Predict: 0.0\n     Else (feature 96 > 0.0)\n      If (feature 87 <= 6.0)\n       If (feature 108 <= 1.0)\n        Predict: 3.0\n       Else (feature 108 > 1.0)\n        Predict: 1.0\n      Else (feature 87 > 6.0)\n       Predict: 3.0\n    Else (feature 5 not in {0.0})\n     If (feature 73 in {0.0})\n      If (feature 98 <= 103.0)\n       If (feature 95 <= 0.0)\n        If (feature 116 <= 0.01)\n         Predict: 1.0\n        Else (feature 116 > 0.01)\n         Predict: 1.0\n       Else (feature 95 > 0.0)\n        Predict: 1.0\n      Else (feature 98 > 103.0)\n       If (feature 74 in {0.0})\n        Predict: 2.0\n       Else (feature 74 not in {0.0})\n        If (feature 111 <= 0.0)\n         Predict: 0.0\n        Else (feature 111 > 0.0)\n         Predict: 2.0\n     Else (feature 73 not in {0.0})\n      Predict: 0.0\n  Tree 3 (weight 1.0):\n    If (feature 98 <= 46.0)\n     If (feature 105 <= 0.04)\n      If (feature 72 in {0.0})\n       If (feature 107 <= 254.0)\n        If (feature 108 <= 2.0)\n         Predict: 2.0\n        Else (feature 108 > 2.0)\n         Predict: 1.0\n       Else (feature 107 > 254.0)\n        If (feature 116 <= 0.51)\n         Predict: 0.0\n        Else (feature 116 > 0.51)\n         Predict: 2.0\n      Else (feature 72 not in {0.0})\n       If (feature 10 in {0.0})\n        If (feature 112 <= 0.1)\n         Predict: 1.0\n        Else (feature 112 > 0.1)\n         Predict: 1.0\n       Else (feature 10 not in {0.0})\n        If (feature 113 <= 0.0)\n         Predict: 2.0\n        Else (feature 113 > 0.0)\n         Predict: 1.0\n     Else (feature 105 > 0.04)\n      If (feature 99 <= 2.0)\n       If (feature 105 <= 0.36)\n        If (feature 98 <= 9.0)\n         Predict: 1.0\n        Else (feature 98 > 9.0)\n         Predict: 0.0\n       Else (feature 105 > 0.36)\n        If (feature 4 in {0.0})\n         Predict: 1.0\n        Else (feature 4 not in {0.0})\n         Predict: 2.0\n      Else (feature 99 > 2.0)\n       If (feature 106 <= 0.0)\n        If (feature 115 <= 0.01)\n         Predict: 0.0\n        Else (feature 115 > 0.01)\n         Predict: 2.0\n       Else (feature 106 > 0.0)\n        If (feature 105 <= 0.25)\n         Predict: 1.0\n        Else (feature 105 > 0.25)\n         Predict: 1.0\n    Else (feature 98 > 46.0)\n     If (feature 107 <= 254.0)\n      If (feature 83 <= 0.0)\n       If (feature 103 <= 0.0)\n        If (feature 72 in {0.0})\n         Predict: 0.0\n        Else (feature 72 not in {0.0})\n         Predict: 0.0\n       Else (feature 103 > 0.0)\n        If (feature 108 <= 2.0)\n         Predict: 2.0\n        Else (feature 108 > 2.0)\n         Predict: 0.0\n      Else (feature 83 > 0.0)\n       If (feature 72 in {0.0})\n        Predict: 2.0\n       Else (feature 72 not in {0.0})\n        If (feature 2 in {0.0})\n         Predict: 1.0\n        Else (feature 2 not in {0.0})\n         Predict: 1.0\n     Else (feature 107 > 254.0)\n      If (feature 104 <= 0.0)\n       If (feature 4 in {0.0})\n        If (feature 105 <= 0.08)\n         Predict: 0.0\n        Else (feature 105 > 0.08)\n         Predict: 2.0\n       Else (feature 4 not in {0.0})\n        If (feature 109 <= 0.0)\n         Predict: 0.0\n        Else (feature 109 > 0.0)\n         Predict: 0.0\n      Else (feature 104 > 0.0)\n       If (feature 89 <= 0.0)\n        If (feature 113 <= 0.57)\n         Predict: 0.0\n        Else (feature 113 > 0.57)\n         Predict: 0.0\n       Else (feature 89 > 0.0)\n        If (feature 110 <= 0.09)\n         Predict: 1.0\n        Else (feature 110 > 0.09)\n         Predict: 2.0\n  Tree 4 (weight 1.0):\n    If (feature 5 in {0.0})\n     If (feature 72 in {0.0})\n      If (feature 115 <= 0.0)\n       If (feature 98 <= 1.0)\n        If (feature 77 in {0.0})\n         Predict: 0.0\n        Else (feature 77 not in {0.0})\n         Predict: 2.0\n       Else (feature 98 > 1.0)\n        If (feature 100 <= 0.33)\n         Predict: 1.0\n        Else (feature 100 > 0.33)\n         Predict: 0.0\n      Else (feature 115 > 0.0)\n       If (feature 100 <= 0.0)\n        If (feature 7 in {0.0})\n         Predict: 0.0\n        Else (feature 7 not in {0.0})\n         Predict: 2.0\n       Else (feature 100 > 0.0)\n        If (feature 109 <= 0.01)\n         Predict: 2.0\n        Else (feature 109 > 0.01)\n         Predict: 0.0\n     Else (feature 72 not in {0.0})\n      If (feature 2 in {0.0})\n       If (feature 105 <= 0.0)\n        If (feature 109 <= 0.99)\n         Predict: 1.0\n        Else (feature 109 > 0.99)\n         Predict: 0.0\n       Else (feature 105 > 0.0)\n        If (feature 111 <= 0.13)\n         Predict: 1.0\n        Else (feature 111 > 0.13)\n         Predict: 1.0\n      Else (feature 2 not in {0.0})\n       If (feature 115 <= 0.88)\n        If (feature 111 <= 0.99)\n         Predict: 1.0\n        Else (feature 111 > 0.99)\n         Predict: 1.0\n       Else (feature 115 > 0.88)\n        If (feature 83 <= 159.0)\n         Predict: 2.0\n        Else (feature 83 > 159.0)\n         Predict: 1.0\n    Else (feature 5 not in {0.0})\n     If (feature 105 <= 0.0)\n      If (feature 114 <= 0.6)\n       If (feature 110 <= 0.75)\n        If (feature 82 <= 1156.0)\n         Predict: 1.0\n        Else (feature 82 > 1156.0)\n         Predict: 0.0\n       Else (feature 110 > 0.75)\n        Predict: 2.0\n      Else (feature 114 > 0.6)\n       Predict: 0.0\n     Else (feature 105 > 0.0)\n      If (feature 83 <= 0.0)\n       If (feature 99 <= 1.0)\n        If (feature 109 <= 0.32)\n         Predict: 0.0\n        Else (feature 109 > 0.32)\n         Predict: 1.0\n       Else (feature 99 > 1.0)\n        Predict: 0.0\n      Else (feature 83 > 0.0)\n       Predict: 1.0\n\n"
                }
            ], 
            "source": "print(rf_model.toDebugString)"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "rf_prediction = rf_model.transform(test)"
        }, 
        {
            "source": "**Check the error and accuracy (The model is actually pretty good)**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nrf_accuracy = evaluator.evaluate(rf_prediction)"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Test Error of RF = 0.00370063 \n"
                }
            ], 
            "source": "print(\"Test Error of RF = %g \" % (1.0 - rf_accuracy))"
        }, 
        {
            "source": "<a id=\"mlp\"></a>\n### Multilayer Perceptron Classifier\nBefore building the MLP model, we need to know how many nodes are needed for the input layer. Check the feature vector:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+\n|            features|\n+--------------------+\n|(117,[1,10,72,82,...|\n|(117,[1,10,72,82,...|\n|(117,[1,10,72,82,...|\n|(117,[1,10,72,82,...|\n|(117,[1,10,72,82,...|\n+--------------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "train.select(\"features\").show(5)"
        }, 
        {
            "source": "**The input layer should have 117 nodes, the output layer should have 5 nodes (5 label categories). I add one hidden layer with 10 nodes to build the model**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Training process takes 874.324070930481 secs\n"
                }
            ], 
            "source": "from pyspark.ml.classification import MultilayerPerceptronClassifier\nlayers = [117, 10, 5]\nmlp = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\nstart_time = time.time()\nmlp_model = mlp.fit(train)\nprint(\"Training process takes %s secs\" % (time.time() - start_time))"
        }, 
        {
            "source": "**Check model performance**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "TypeError", 
                    "evalue": "Can't convert 'float' object to str implicitly", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-16-d32f6347f912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmlp_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Error of MLP = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;31mTypeError\u001b[0m: Can't convert 'float' object to str implicitly"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "mlp_predictions = mlp_model.transform(test)\naccuracy = evaluator.evaluate(mlp_predictions)\nprint(\"Test Error of MLP = \" + (1.0 - accuracy))"
        }, 
        {
            "source": "<a id=\"summary\"></a>\n## Summary and next steps     \n**Two well-performing models are built in this notebook. It is very easy to build models using Spark API!**\n\n**There is no need to configure the Spark environment in Watson Studio. Just provision the Spark environment, create the notebook and you are ready to write your code!**\n\n**The speed of the Spark enviornment is not bad. However it is much faster if coding in Scala(Check my another demo on using Scala to build the exact same models with the same runtime).**\n\nNext steps:\n* Save/download the models to local\n* Save and deploy the models using Watson Machine Learning Service(WML)\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "name": "python3", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}