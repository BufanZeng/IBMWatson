{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "Waiting for a Spark session to start..."
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "credentials = Map(apiKey -> UC2EdaFY_rERXSOZHgTciY1Prmqsnc4aGwpCzOSFun__, serviceId -> iam-ServiceId-d7c9135c-9c60-45fb-970a-c90d813805c4, endPoint -> https://s3-api.us-geo.objectstorage.service.networklayer.com, iamServiceEndpoint -> https://iam.ng.bluemix.net/oidc/token)\nconfigurationName = os_45ef92514c2049f5ad540ea2a90e5504_configs\ncos = com.ibm.ibmos2spark.CloudObjectStorage@21023a86\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 1, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "com.ibm.ibmos2spark.CloudObjectStorage@21023a86"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "// The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "Waiting for a Spark session to start..."
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "starttime = 1528902157828\ntest = MapPartitionsRDD[2] at filter at <console>:38\ntestheader = userID,productID,rating\ntest = MapPartitionsRDD[2] at filter at <console>:38\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 2, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "MapPartitionsRDD[2] at filter at <console>:38"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val starttime = System.currentTimeMillis()\nvar test = sc.textFile(cos.url(\"bufantest-donotdelete-pr-tkuiqj2r7rommw\", \"video_small_testing_num.csv\"))\nval testheader = test.first()\ntest = test.filter(x=>x!=testheader)"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "train = MapPartitionsRDD[5] at filter at <console>:37\ntrainheader = userID,productID, rating, timestamp\ntrain = MapPartitionsRDD[5] at filter at <console>:37\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "MapPartitionsRDD[5] at filter at <console>:37"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "var train = sc.textFile(cos.url(\"bufantest-donotdelete-pr-tkuiqj2r7rommw\", \"video_small_num.csv\"))\nval trainheader = train.first()\ntrain = train.filter(x=>x!=trainheader)"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "test_ratings = MapPartitionsRDD[7] at map at <console>:39\ntrain_ratings = MapPartitionsRDD[9] at map at <console>:40\nratings = MapPartitionsRDD[10] at map at <console>:41\nusersProducts = MapPartitionsRDD[11] at map at <console>:45\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "MapPartitionsRDD[11] at map at <console>:45"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val test_ratings = test.map(_.split(',')).map(row=> (row(0).toInt, row(1).toInt, row(2).toDouble))\nval train_ratings = train.map(_.split(',')).map(row => (row(0).toInt, row(1).toInt, row(2).toDouble))\nval ratings = train_ratings.map(\n            info => {\n                Rating(info._1, info._2, info._3)\n        })\nval usersProducts = test_ratings.map (row => {(row._1, row._2)})\n"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "rank = 5\nnumIterations = 10\nlambda = 0.5\nseed = 1\nmodel = org.apache.spark.mllib.recommendation.MatrixFactorizationModel@73360b7d\npredictions = MapPartitionsRDD[227] at map at <console>:52\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "MapPartitionsRDD[227] at map at <console>:52"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val rank = 5\nval numIterations = 10\nval lambda = 0.5\nval seed = 1\nval model = ALS.train(ratings, rank, numIterations, lambda, -1, seed)\n//        val model = ALS.train(ratings, rank, numIterations,0.01)\n\nvar predictions = model.predict(usersProducts)\n        .map { case Rating(user, product, rate) =>((user, product), rate)}\n"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "min = -3.7682779979313046\nmax = 5.182124623439929\nresult = MapPartitionsRDD[230] at map at <console>:53\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "MapPartitionsRDD[230] at map at <console>:53"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val min = predictions.map(_._2).min()\nval max = predictions.map(_._2).max()\nvar result = predictions.map{case ((user, product), rate) =>\n    ((user, product), 4.0 * (rate-min)/(max - min) + 1.0)\n\n}"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": ">=0 and <1: 4845\n>=1 and <2: 1944\n>=2 and <3: 515\n>=3 and <4: 396\n>=4: 0\nRMSE: 1.2947936470436476\nTime: 76 sec\n"
                }
            ], 
            "source": "val ratesAndPreds = test_ratings.map { case (user, product, rate) =>\n            ((user, product), rate)\n        }.join(result)\nval diff = ratesAndPreds.map{case ((user, product), (r1, r2)) =>\nmath.abs(r1 - r2)}\nval RMSE = math.sqrt(diff.map(x=>{x * x}).mean())\nvar range1 = diff.filter{ case (diff) => diff>=0 && diff<1}.count()\nvar range2 = diff.filter{ case (diff) => diff>=1 && diff<2}.count()\nvar range3 = diff.filter{ case (diff) => diff>=2 && diff<3}.count()\nvar range4 = diff.filter{ case (diff) => diff>=3 && diff<4}.count()\nvar range5 = diff.filter{ case (diff) => diff>=4}.count()\nprintln(\">=0 and <1: \"+range1)\nprintln(\">=1 and <2: \"+range2)\nprintln(\">=2 and <3: \"+range3)\nprintln(\">=3 and <4: \"+range4)\nprintln(\">=4: \"+range5)\nprintln(\"RMSE: \"+ RMSE)\nprintln(\"Time: \"+ ((System.currentTimeMillis()-starttime)/1000).toString +\" sec\")\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Scala 2.11 with Spark", 
            "name": "scala", 
            "language": "scala"
        }, 
        "language_info": {
            "mimetype": "text/x-scala", 
            "version": "2.11.8", 
            "name": "scala", 
            "pygments_lexer": "scala", 
            "file_extension": ".scala", 
            "codemirror_mode": "text/x-scala"
        }
    }, 
    "nbformat": 4
}